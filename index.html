<!DOCTYPE html>
<head>
	<title>Facial-Micro-Expression-Grand-challenge</title>
    <meta charset="UTF-8">
	<meta name="keywords" content="" />
	<meta name="description" content="" />
    <!-- 
    Division Template
    http://www.templatemo.com/preview/templatemo_448_division
    -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link href="css/templatemo_style.css" rel="stylesheet" type="text/css">
</head>
<body>
	<div class="main-container">
		<div class="col-xs-12 visible-sm visible-xs" id="templatemo_mobile_menu_wap">
			<p id="mobile_menu_btn"> <a href="#"><span class="fa fa-bars"></span></a> </p>
			<div id="mobile_menu">
				<ul class="nav nav-pills nav-stacked navbar-collapse in">
					
					<li id="page2_link_m">About</li>
					<li id="page3_link_m">Submissions</li>
					<li id="page4_link_m">Organizers</li>
					<li id="page5_link_m">Speakers</li>
					<li id="page6_link_m">Contact</li>
					<li><a href="http://www.google.com" class="external">External</a></li>
				</ul>
			</div>
		</div>
		<div class="templatemo-header">
			<div id="logo" class="pull-left">MEGC2019</div>
			<nav class="hidden-sm hidden-xs pull-right">			
				<ul>
					
					<li id="page2_link_m">About</li>
					<li id="page3_link_m">Submissions</li>
					<li id="page4_link_m">Organizers</li>
					<li id="page5_link_m">Speakers</li>
					<li id="page6_link_m">Contact</li>
					<li><a href="http://www.google.com" class="external">External</a></li>
				</ul>
			</nav>
		</div>
		

		<section class="page" id="page2">
			<h1 class="hide">About</h1>
			<div class="page-container">
				<div class="page-content padding">
					
					<h1>The Second Facial Micro-Expression Grand Challenge (MEGC): Spotting and Recognition</h1>
					<br />
					<h2>Workshop motivation, expected outcomes and impact</h2><br />

<p>Facial micro-expressions (MEs) are involuntary movements of the face that occur spontaneously when a person experiences an emotion but attempts to suppress or repress the facial expression, typically found in a high-stakes environment. As such, the duration of MEs is very short with the general duration of not more than 500 milliseconds (ms), and is the telltale sign that distinguishes them from a normal facial expression. Computational analysis and automation of tasks on micro-expressions is an emerging area in face research, with a strong interest appearing as recent as 2014. Only recently, the availability of a few spontaneously induced facial micro-expression datasets has provided the impetus to advance further from the computational aspect. Particularly comprehensive

are two state-of-the-art FACS coded datasets: the Chinese Academy of Sciences Micro-Expression Database II (CASME II) with 247 MFEs at 200 fps and the Spontaneous Facial Micro-Movement Dataset (SAMM) with 159 MFEs at 200 fps. In addition, there is recent interest in acquiring “in-the-wild” datasets to further introduce real-world scenarios. While much research has been done on these datasets individually, there have been little attempts to introduce a more rigorous and realistic evaluation to work done in this domain.

This is the second edition of this workshop, which aims to promote interactions between researchers and scholars not only from within this niche area of facial micro-expression research, but also including those from broader, general areas of expression and psychology research.</p>

					<h2> This workshop has two main agenda:</h2>
					<br />
					<br />
				        <p>To organize the Second Grand Challenge for facial micro-expression research,<br />
						involving cross-database recognition and spotting of micro-expressions.</p>
					<p><a href="http://www2.docm.mmu.ac.uk/STAFF/m.yap/files/MEGC_Guidelines.pdf" class = " ">Download guidance here</a></p>
					<p>To solicit original works that address a variety of challenges of ME research,but not limited to</p>
					<br/>
					<br/>
					<p>ME spotting/detection</p>
					<p>ME recognition</p>
					<p>ME feature representation and computational analysis</p>
					<p>Unified ME spot-and-recognize schemes</p>
					<p>Deep learning techniques for MEs spotting and recognition</p>
					<p>MEs data analysis and synthesis</p>
					<p>New datasets for MEs</p>
					<p>Psychology of MEs</p>
				<img src="images/team/Moi.jpeg" alt="about" class="bordered">
				</div>				
			</div>	    
		</section>
		
		<section class="page services" id="page3">
			<h1>Submissions</h1>
			<div class="page-container">
				<div class="templatemo-item">
					<!-- To change icons, see http://fortawesome.github.io/Font-Awesome/icons/ -->
					<!--<i class="fa fa-cog rounded"></i>-->
					<h3>Advisory Panel:</h3>
					<p>Xiaolan Fu, Chinese Academy of Sciences, China</p>
					<br />
					<br />
					<p>Guoying Zhao, University of Oulu, Finland<p><br />
				</div>
				<div class="templatemo-item">
					<!--<i class="fa fa-html5 rounded"></i>-->
					<h3>Tentative length of the workshop (half day or full day)</h3>
					<p>Full day.</p>
				</div>
				<div class="templatemo-item">
					<!--<i class="fa fa-star rounded"></i>-->
					<h3>Tentative paper submission and review schedule</h3>
					<p>Submission deadline: 27 January 2019</p><br />
					<br />
					<p>Notification: 12 February 2019<br />
					<br />
					<p>Camera-ready: 15 February 2019</p>
				</div>
				<div class="templatemo-item">
					<!--<i class="fa fa-cubes rounded"></i>-->
					<h3>Planned advertisement means, website hosting</h3>
					<p><a href="https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FMEGC2018" class="templatemo-item">Submit paper here</a></p>
					<p>Workshop will be advertised at various websites, and by email circulation and social media.</p>
				</div>
				<div class="templatemo-item">
					<!--<i class="fa fa-database rounded"></i>-->
					
					<h3>Paper submission procedure (submission via web site, via email, etc.) if applicable </h3>
					<p><a href ="https://fg2018.cse.sc.edu/submissions.html.">submit instructions here</a></p>
					<p>Easy chair / CMT (tbc) </p>
				</div>
				<div class="templatemo-item">
					<!--<i class="fa fa-mobile rounded"></i>-->
					<h3>Paper review procedure (single/double-blind, internal/external, solicited/invited-only,pool of reviewers, etc.)</h3>
					<p>Double-blind, each paper to be reviewed by a minimum of 2 reviewers</p>
				</div>
				<div class="templatemo-item">
					<!--<i class="fa fa-mobile rounded"></i>-->
					<h3>Estimated number of submissions and acceptance rate</h3>
					<p>30 submissions with acceptance rate 40%.</p>
				</div>
				<div class="templatemo-item">
					<!--<i class="fa fa-mobile rounded"></i>-->
					<h3>Special space or equipment requests, if any</h3>
					<p>N/A</p>
				</div>
				<div class="templatemo-item">
					<!--<i class="fa fa-mobile rounded"></i>-->
					<h3>Specify if there will be non-peer reviewed invited paper, if so, how many?</h3>
					<p>N/A</p>
				</div>			
			</div>			
		</section>
		<section class="page team" id="page4">
			<h1>Organizers</h1></br>
			<h1>List of organizers including affiliation, email address, and short bio</h1>
			<div class="page-container">
				<div class="templatemo-item">
					<img src="images/team/Moi.jpeg" alt="Team member 1" class="bordered">
					<h3>Moi Hoon Yap</h3>		
	<p>Manchester Metropolitan University,UK, m.yap@mmu.ac.uk<br />
	Moi Hoon Yap received her PhD in Computer Science from Loughborough University in 2009.<br />
	She is a Reader (Associate Professor) in Computer Vision at the Manchester Metropolitan University and a Royal Society Industry Fellow with Image Metrics Ltd.<br />
	She leads the Human-Centred Computing Group and the lead contributor of SAMM dataset.<br />
	Her research is funded by The Royal Society, EU funding, Innovate UK and industrial funding.<br />
	Her research expertise is in computer vision, deep learning, image/video processing on face and gesture analysis.</p>


					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>                	
				</div>
				<div class="templatemo-item">
					<img src="images/team/cv.jpg" alt="Team member 2" class="bordered">
					<h3>Sujing Wang</h3>
	 <p>Chinese Academy of Sciences, China, wangsujing@psych.ac.cn.<br />
	 Sujing Wang received his Master's degree from the Software College of Jilin University, Changchun, China, in 2007.<br />
	 He received the Ph.D. degree from the College of Computer Science and Technology of Jilin University in 2012.<br />
         He was a postdoctoral researcher in Institute of Psychology, Chinese Academy of Sciences from 2012 to 2015.<br />
	 He is now an Associate Researcher in Institute of Psychology, Chinese Academy of Sciences.<br />
         He has published more than 50 scientific papers.<br />
         He is One of Ten Selectees of the Doctoral Consortium at International Joint Conference on Biometrics 2011.<br />
	 He was called as Chinese Hawkin by the Xinhua News Agency. His current research interests include pattern recognition,<br /> 
	 computer vision and machine learning. He serves as an associate editor of Neurocomputing (Elsevier).</p>

					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>    
				</div>
				<div class="templatemo-item">
					<img src="images/team/johnsee.jpg" alt="Team member 3" class="bordered">
					<h3>John See</h3>
	<p>Multimedia University, Malaysia, johnsee@mmu.edu.my<br/>
	John See received his PhD in Computer Science, MEngSc and BEng degrees from Multimedia University (MMU), Malaysia.<br />
	He is currently a Senior Lecturer at Multimedia University where he leads the Visual Processing Laboratory under the Centre for Visual Computing.<br />
	He is also currently a Visiting Research Fellow to Shanghai Jiao Tong University, China.<br />
	Dr. See has published more than 50 articles in reputable journals and conferences such as IEEE T-AC, IEEE T-CE, ICCV, ICIP, ACCV, and FG,<br />
	and has also served as chair of several workshops and special sessions in various international computer vision and signal processing conferences worldwide.<br />
	He will be serving as Program Chair in IEEE MMSP 2019. His research interests cover a diverse range of topics in computer vision and pattern recognition, <br />
	particularly in the emerging fields of facial biometrics, affective computing, computational aesthetics and deep learning.</p>
					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>
				</div>
				<div class="templatemo-item">
					<img src="images/team/Xiaopeng_Hong.jpg" alt="Team member 2" class="bordered">
					<h3>Xiaopeng Hong,</h3>
					<p>University of Oulu, Finland, hongxiaopeng.cn@gmail.com</p>
					<p>Xiaopeng Hong received his BEng and Ph.D. degrees in computer application and technology from Harbin Institute of Technology, Harbin, P. R. China, in 2004 and 2010 respectively. He is currently a Docent with the Center for Machine Vision and Signal Analysis, University of Oulu, Finland, where he has been a scientist researcher since 2011. Dr. Hong has published over 30 articles in mainstream journals and conferences such as IEEE T-PAMI, IEEE T-IP, IEEE CVPR and ACM UbiComp, and have one issued Chinese Patent. He has organized two international workshops and served as a reviewer for about 30 journals and conferences. His current research interests include the deep learning technology and other machine learning methods, especially their applications in multi-modal learning, affective computing, intelligent medical examination, and human-computer interaction, etc. His research has been reported by global media including MIT Technology Review and Daily Mail.</p
</p>
					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>                	
				</div>
				<div class="templatemo-item">
					<img src="images/team/member3.jpg" alt="Team member 3" class="bordered">
					<h3>Developer</h3>
					<p>Ut quis diam porttitor, dictum dolor in, volutpat nulla porttitor.</p>
					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>    
				</div>
				<div class="templatemo-item">
					<img src="images/team/member1.jpg" alt="Team member 1" class="bordered">
					<h3>Designer</h3>
					<p>Praesent id mauris eu urna vehicula rutrum sed in elit.</p>
					<div class="social">
						<a href=""><i class="fa fa-twitter circle"></i></a>
						<a href=""><i class="fa fa-facebook circle"></i></a>
						<a href=""><i class="fa fa-linkedin circle"></i></a>
					</div>
				</div>
			</div>			
		</section>
		<section class="page contact" id="page5">
			<div class="page-container">
				<div class="page-content padding">
					<h1>Keynote Speakers</h1>
					<p>TBC!</p>
					<h2>Tentative program committee, and invited speakers, if any</h2>
					<p>TPC:</p>
					<p>Adrian Keith Davison, University of Manchester, UK </p><br />
					<p>Daniel Leightley, King’s College London, UK</p><br />
					<p>Anh Cat Le Ngo, University of Nottingham, UK</p><br />
					<p>Sze Teng Liong, Feng Chia University, Taiwan</p><br />
					<p>Walied Merghani, Sudan University of Science and Technology, Sudan</p><br />
					<p>Xiaoyi Feng, Northwestern Polytechnical University, Xi’an, China</p><br />
					<p>Ruiping Wang, Institute of Computing Technology, Chinese Academy of Sciences, China</p>
					<p>Xiaobai Li, University of Oulu, Finland </p><br />
					<p>Wenjing Yan, Wenzhou University, China</p><br />
					<p>Choon-Ching Ng, PRDCSG, Singapore</p><br />
					<p>Hongying Meng, Brunel University, UK </p><br />
					<p>Zhen Cui, Nanjing University of Science and Technology, China</p><br />
					<p>Zhaoqiang Xia, Northwestern Polytechnical University, China</p><br />
					<p>Yannick Benezeth, Univ Bourgogne Franche-Comté</p><br />
					<br />

					<p>Invited Speakers: 2 speakers (tbc) </p>
					
					
					
							
				</div>							
			</div> 			       	                
		</section>

                <section class="page contact" id="page6">
			<div class="page-container">
				<div class="page-content padding">
					<h1>Contact Us</h1>
					<p> Fill in the form below to request further information!</p>
					<div class="map-contact-container">
						<div id="map"></div>
						<div class="contact-form">
							<form>
								<input type="text" name="name" id="name" placeholder="Name">
								<input type="email" name="email" id="email" placeholder="Email">
								<input type="text" name="subject" id="subject" placeholder="Subject">
								<textarea name="comments" id="comments" placeholder="Message"></textarea>
								<button type="submit">SEND</button>
							</form>		
						</div>	
					</div>		
				</div>							
			</div> 			       	                
		</section>
		<!-- footer code is injected from "js/templatemo_script.js", change at line 32 -->
	</div>
	<script src="js/jquery-1.11.1.min.js"></script>	
	<script src="js/jquery.easing-1.3.js"></script>
	<script src="js/plugins.js"></script>
	
<script src="js/bootstrap.min.js"></script>
<script src="js/templatemo_script.js"></script>
</body>
</html>
